{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntino\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
      "1  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25       0.004793   \n",
      "2  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00       0.004783   \n",
      "3  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50       0.004779   \n",
      "4  2015-02-04 17:54:00        23.15   27.2000  426.0  708.25       0.004772   \n",
      "5  2015-02-04 17:55:00        23.10   27.2000  426.0  704.50       0.004757   \n",
      "\n",
      "   Occupancy  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n",
      "5          1  \n",
      "     0     1     2    3     4     5     6     7     8     9  ...    48     49  \\\n",
      "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
      "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
      "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
      "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
      "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
      "\n",
      "    50     51     52     53     54   55    56  57  \n",
      "0  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
      "1  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
      "2  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
      "3  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
      "4  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "occupancy_df_training = pd.read_csv(\"occupancy_data/datatraining.txt\", header=0)\n",
    "\n",
    "print(occupancy_df_training.head())\n",
    "\n",
    "occupancy_df_test1 = pd.read_csv(\"occupancy_data/datatest.txt\", header=0)\n",
    "occupancy_df_test2 = pd.read_csv(\"occupancy_data/datatest2.txt\", header=0)\n",
    "\n",
    "spambase_df = pd.read_csv(\"spambase/spambase.data\", header=None)\n",
    "\n",
    "print(spambase_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2    3     4     5     6     7     8     9   ...    47    48  \\\n",
      "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...   0.0  0.00   \n",
      "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...   0.0  0.00   \n",
      "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...   0.0  0.01   \n",
      "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...   0.0  0.00   \n",
      "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...   0.0  0.00   \n",
      "\n",
      "      49   50     51     52     53     54   55    56  \n",
      "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278  \n",
      "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028  \n",
      "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259  \n",
      "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191  \n",
      "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "occupancy_y = occupancy_df_training.Occupancy\n",
    "\n",
    "occupancy_df_training = occupancy_df_training.drop(\"Occupancy\", axis=1)\n",
    "occupancy_df_training = occupancy_df_training.drop(\"date\", axis=1)\n",
    "\n",
    "spambase_y = spambase_df[57]\n",
    "spambase_df = spambase_df.drop(57, axis=1)\n",
    "print(spambase_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split with KFolds\n",
    "kf = KFold(10, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with 2 layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.sigmoid)) # 16 neurons and sigmoid activation function\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid)) # 1 neuron and sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7328/7328 [==============================] - 0s 52us/step - loss: 0.4517 - acc: 0.7908 - f1_m: 0.0487\n",
      "Epoch 2/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.3645 - acc: 0.8225 - f1_m: 0.3114\n",
      "Epoch 3/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.2888 - acc: 0.9101 - f1_m: 0.7785\n",
      "Epoch 4/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.2485 - acc: 0.9166 - f1_m: 0.8044\n",
      "Epoch 5/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.2272 - acc: 0.9166 - f1_m: 0.8034\n",
      "Epoch 6/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.2118 - acc: 0.9170 - f1_m: 0.8093\n",
      "Epoch 7/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.2004 - acc: 0.9169 - f1_m: 0.8091\n",
      "Epoch 8/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.1910 - acc: 0.9176 - f1_m: 0.8110\n",
      "Epoch 9/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1816 - acc: 0.9183 - f1_m: 0.8131\n",
      "Epoch 10/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.1711 - acc: 0.9178 - f1_m: 0.8097\n",
      "815/815 [==============================] - 0s 77us/step\n",
      "Epoch 1/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1457 - acc: 0.9198 - f1_m: 0.8114\n",
      "Epoch 2/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1319 - acc: 0.9243 - f1_m: 0.8217\n",
      "Epoch 3/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.1168 - acc: 0.9363 - f1_m: 0.8504\n",
      "Epoch 4/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.1009 - acc: 0.9618 - f1_m: 0.9080\n",
      "Epoch 5/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.0957 - acc: 0.9709 - f1_m: 0.9275\n",
      "Epoch 6/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0896 - acc: 0.9742 - f1_m: 0.9372\n",
      "Epoch 7/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0846 - acc: 0.9769 - f1_m: 0.9425\n",
      "Epoch 8/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0810 - acc: 0.9790 - f1_m: 0.9466\n",
      "Epoch 9/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0771 - acc: 0.9816 - f1_m: 0.9539\n",
      "Epoch 10/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0712 - acc: 0.9835 - f1_m: 0.9604\n",
      "815/815 [==============================] - 0s 10us/step\n",
      "Epoch 1/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.0656 - acc: 0.9834 - f1_m: 0.9556\n",
      "Epoch 2/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0608 - acc: 0.9839 - f1_m: 0.9533\n",
      "Epoch 3/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0576 - acc: 0.9857 - f1_m: 0.9651\n",
      "Epoch 4/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0576 - acc: 0.9846 - f1_m: 0.9614\n",
      "Epoch 5/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0564 - acc: 0.9853 - f1_m: 0.9633\n",
      "Epoch 6/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0560 - acc: 0.9849 - f1_m: 0.9643\n",
      "Epoch 7/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.0542 - acc: 0.9853 - f1_m: 0.9663\n",
      "Epoch 8/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.0536 - acc: 0.9857 - f1_m: 0.9652\n",
      "Epoch 9/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.0522 - acc: 0.9858 - f1_m: 0.9633\n",
      "Epoch 10/10\n",
      "7328/7328 [==============================] - 0s 21us/step - loss: 0.0521 - acc: 0.9864 - f1_m: 0.9676\n",
      "815/815 [==============================] - 0s 11us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0505 - acc: 0.9865 - f1_m: 0.9661\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0490 - acc: 0.9870 - f1_m: 0.9654\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0490 - acc: 0.9870 - f1_m: 0.9663\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0481 - acc: 0.9865 - f1_m: 0.9665\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0480 - acc: 0.9858 - f1_m: 0.9659\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0482 - acc: 0.9855 - f1_m: 0.9594\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0477 - acc: 0.9866 - f1_m: 0.9666\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0474 - acc: 0.9873 - f1_m: 0.9637\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0468 - acc: 0.9880 - f1_m: 0.9677\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0468 - acc: 0.9870 - f1_m: 0.9654\n",
      "814/814 [==============================] - 0s 12us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0447 - acc: 0.9877 - f1_m: 0.9704\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0451 - acc: 0.9872 - f1_m: 0.9691\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0443 - acc: 0.9881 - f1_m: 0.9704\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0446 - acc: 0.9872 - f1_m: 0.9689\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0441 - acc: 0.9870 - f1_m: 0.9679\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0437 - acc: 0.9879 - f1_m: 0.9719\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0429 - acc: 0.9884 - f1_m: 0.9728\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0436 - acc: 0.9880 - f1_m: 0.9724\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0442 - acc: 0.9869 - f1_m: 0.9667\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0424 - acc: 0.9887 - f1_m: 0.9708\n",
      "814/814 [==============================] - 0s 10us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 25us/step - loss: 0.0459 - acc: 0.9870 - f1_m: 0.9677\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0452 - acc: 0.9876 - f1_m: 0.9709\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0460 - acc: 0.9862 - f1_m: 0.9632\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0450 - acc: 0.9870 - f1_m: 0.9672\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0458 - acc: 0.9864 - f1_m: 0.9647\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0445 - acc: 0.9872 - f1_m: 0.9686\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 0.0440 - acc: 0.9880 - f1_m: 0.9710\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 24us/step - loss: 0.0440 - acc: 0.9879 - f1_m: 0.9685\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0430 - acc: 0.9876 - f1_m: 0.9692\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0426 - acc: 0.9883 - f1_m: 0.9685\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0400 - acc: 0.9891 - f1_m: 0.9748\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0404 - acc: 0.9884 - f1_m: 0.9654\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0387 - acc: 0.9896 - f1_m: 0.9750\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 0.0383 - acc: 0.9900 - f1_m: 0.9737\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 27us/step - loss: 0.0390 - acc: 0.9899 - f1_m: 0.9750\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 25us/step - loss: 0.0391 - acc: 0.9894 - f1_m: 0.9731\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 0.0384 - acc: 0.9889 - f1_m: 0.9725\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 0.0399 - acc: 0.9881 - f1_m: 0.9693\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 27us/step - loss: 0.0387 - acc: 0.9902 - f1_m: 0.9735\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 0.0386 - acc: 0.9885 - f1_m: 0.9702\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0405 - acc: 0.9885 - f1_m: 0.9660\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 0.0404 - acc: 0.9888 - f1_m: 0.9701\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 0.0424 - acc: 0.9885 - f1_m: 0.9701\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 24us/step - loss: 0.0405 - acc: 0.9892 - f1_m: 0.9733\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0419 - acc: 0.9879 - f1_m: 0.9711\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 0.0409 - acc: 0.9884 - f1_m: 0.9707\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0391 - acc: 0.9891 - f1_m: 0.9698\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0410 - acc: 0.9889 - f1_m: 0.9729\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0410 - acc: 0.9883 - f1_m: 0.9675\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0410 - acc: 0.9885 - f1_m: 0.9694\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0404 - acc: 0.9884 - f1_m: 0.9705\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0403 - acc: 0.9885 - f1_m: 0.9716\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0405 - acc: 0.9889 - f1_m: 0.9724\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 0.0414 - acc: 0.9887 - f1_m: 0.9711\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0453 - acc: 0.9880 - f1_m: 0.9706\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 0.0418 - acc: 0.9884 - f1_m: 0.9698\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0401 - acc: 0.9891 - f1_m: 0.9729\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0412 - acc: 0.9884 - f1_m: 0.9713\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0414 - acc: 0.9891 - f1_m: 0.9713\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0404 - acc: 0.9887 - f1_m: 0.9730\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0409 - acc: 0.9887 - f1_m: 0.9637\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0407 - acc: 0.9892 - f1_m: 0.9719\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0414 - acc: 0.9885 - f1_m: 0.9707\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0410 - acc: 0.9877 - f1_m: 0.9690\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0408 - acc: 0.9887 - f1_m: 0.9712\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0403 - acc: 0.9891 - f1_m: 0.9733\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0404 - acc: 0.9892 - f1_m: 0.9739\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0415 - acc: 0.9880 - f1_m: 0.9682\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 39us/step - loss: 0.0408 - acc: 0.9891 - f1_m: 0.9735\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 26us/step - loss: 0.0409 - acc: 0.9889 - f1_m: 0.9715\n",
      "814/814 [==============================] - 0s 14us/step\n",
      "\n",
      "accuracy:   0.980, f1_score:   0.375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_accuracy = 0\n",
    "overall_f1_score = 0\n",
    "for train, test in kf.split(occupancy_df_training):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = occupancy_df_training.iloc[train], occupancy_df_training.iloc[test], occupancy_y.iloc[train], occupancy_y.iloc[test]\n",
    "    \n",
    "    history = model.fit(X_train.values,\n",
    "                        y_train.values,\n",
    "                        epochs=10)\n",
    "    \n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    loss, accuracy, f1 = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    overall_accuracy += accuracy\n",
    "    overall_f1_score += f1\n",
    "    \n",
    "print(\"\\naccuracy:   %0.3f, f1_score:   %0.3f\\n\" % (overall_accuracy/10, overall_f1_score/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with 2 layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.sigmoid, input_shape=(57,))) # 16 neurons and sigmoid activation function\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid, input_shape=(57,))) # 1 neuron and sigmoid activation function\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4140/4140 [==============================] - 0s 99us/step - loss: 0.6428 - acc: 0.6060 - f1_m: 0.0011\n",
      "Epoch 2/5\n",
      "4140/4140 [==============================] - 0s 24us/step - loss: 0.5648 - acc: 0.6635 - f1_m: 0.2372\n",
      "Epoch 3/5\n",
      "4140/4140 [==============================] - 0s 28us/step - loss: 0.4741 - acc: 0.8010 - f1_m: 0.6893\n",
      "Epoch 4/5\n",
      "4140/4140 [==============================] - 0s 23us/step - loss: 0.4028 - acc: 0.8623 - f1_m: 0.8116\n",
      "Epoch 5/5\n",
      "4140/4140 [==============================] - 0s 21us/step - loss: 0.3491 - acc: 0.8843 - f1_m: 0.8439\n",
      "461/461 [==============================] - 0s 176us/step\n",
      "Epoch 1/5\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 0.3081 - acc: 0.9015 - f1_m: 0.8703\n",
      "Epoch 2/5\n",
      "4141/4141 [==============================] - 0s 25us/step - loss: 0.2756 - acc: 0.9152 - f1_m: 0.8894\n",
      "Epoch 3/5\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 0.2579 - acc: 0.9150 - f1_m: 0.8884\n",
      "Epoch 4/5\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 0.2408 - acc: 0.9215 - f1_m: 0.8984\n",
      "Epoch 5/5\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 0.2207 - acc: 0.9268 - f1_m: 0.9048\n",
      "460/460 [==============================] - 0s 13us/step\n",
      "Epoch 1/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.2200 - acc: 0.9247 - f1_m: 0.9008\n",
      "Epoch 2/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.2101 - acc: 0.9280 - f1_m: 0.9056\n",
      "Epoch 3/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1980 - acc: 0.9319 - f1_m: 0.9098\n",
      "Epoch 4/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1959 - acc: 0.9348 - f1_m: 0.9133\n",
      "Epoch 5/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1872 - acc: 0.9353 - f1_m: 0.9140\n",
      "460/460 [==============================] - 0s 15us/step\n",
      "Epoch 1/5\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 0.1944 - acc: 0.9305 - f1_m: 0.9081\n",
      "Epoch 2/5\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 0.1863 - acc: 0.9333 - f1_m: 0.9118\n",
      "Epoch 3/5\n",
      "4141/4141 [==============================] - 0s 25us/step - loss: 0.1794 - acc: 0.9362 - f1_m: 0.9123\n",
      "Epoch 4/5\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 0.1775 - acc: 0.9379 - f1_m: 0.9156\n",
      "Epoch 5/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1745 - acc: 0.9358 - f1_m: 0.9140\n",
      "460/460 [==============================] - 0s 20us/step\n",
      "Epoch 1/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1750 - acc: 0.9387 - f1_m: 0.9207\n",
      "Epoch 2/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1834 - acc: 0.9326 - f1_m: 0.9101\n",
      "Epoch 3/5\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 0.1784 - acc: 0.9370 - f1_m: 0.9177\n",
      "Epoch 4/5\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 0.1720 - acc: 0.9408 - f1_m: 0.9237\n",
      "Epoch 5/5\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 0.1712 - acc: 0.9389 - f1_m: 0.9209\n",
      "460/460 [==============================] - 0s 39us/step\n",
      "Epoch 1/5\n",
      "4141/4141 [==============================] - 0s 26us/step - loss: 0.1695 - acc: 0.9389 - f1_m: 0.9180\n",
      "Epoch 2/5\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 0.1678 - acc: 0.9394 - f1_m: 0.9201\n",
      "Epoch 3/5\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 0.1635 - acc: 0.9425 - f1_m: 0.9250\n",
      "Epoch 4/5\n",
      "4141/4141 [==============================] - 0s 25us/step - loss: 0.1615 - acc: 0.9437 - f1_m: 0.9250\n",
      "Epoch 5/5\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 0.1604 - acc: 0.9433 - f1_m: 0.9259\n",
      "460/460 [==============================] - 0s 15us/step\n",
      "Epoch 1/5\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 0.1661 - acc: 0.9384 - f1_m: 0.9197\n",
      "Epoch 2/5\n",
      "4141/4141 [==============================] - 0s 25us/step - loss: 0.1636 - acc: 0.9428 - f1_m: 0.9269\n",
      "Epoch 3/5\n",
      "4141/4141 [==============================] - 0s 25us/step - loss: 0.1661 - acc: 0.9399 - f1_m: 0.9221\n",
      "Epoch 4/5\n",
      "4141/4141 [==============================] - 0s 32us/step - loss: 0.1710 - acc: 0.9375 - f1_m: 0.9200\n",
      "Epoch 5/5\n",
      "4141/4141 [==============================] - 0s 27us/step - loss: 0.1648 - acc: 0.9404 - f1_m: 0.9214\n",
      "460/460 [==============================] - 0s 13us/step\n",
      "Epoch 1/5\n",
      "4141/4141 [==============================] - 0s 29us/step - loss: 0.1603 - acc: 0.9428 - f1_m: 0.9258\n",
      "Epoch 2/5\n",
      "4141/4141 [==============================] - 0s 28us/step - loss: 0.1638 - acc: 0.9416 - f1_m: 0.9233\n",
      "Epoch 3/5\n",
      "4141/4141 [==============================] - 0s 26us/step - loss: 0.1614 - acc: 0.9447 - f1_m: 0.9292\n",
      "Epoch 4/5\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 0.1623 - acc: 0.9416 - f1_m: 0.9236\n",
      "Epoch 5/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1613 - acc: 0.9435 - f1_m: 0.9248\n",
      "460/460 [==============================] - 0s 13us/step\n",
      "Epoch 1/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1535 - acc: 0.9457 - f1_m: 0.9291\n",
      "Epoch 2/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1584 - acc: 0.9445 - f1_m: 0.9285\n",
      "Epoch 3/5\n",
      "4141/4141 [==============================] - 0s 27us/step - loss: 0.1540 - acc: 0.9437 - f1_m: 0.9291\n",
      "Epoch 4/5\n",
      "4141/4141 [==============================] - 0s 26us/step - loss: 0.1617 - acc: 0.9430 - f1_m: 0.9267\n",
      "Epoch 5/5\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 0.1565 - acc: 0.9464 - f1_m: 0.9319\n",
      "460/460 [==============================] - 0s 13us/step\n",
      "Epoch 1/5\n",
      "4141/4141 [==============================] - ETA: 0s - loss: 0.1589 - acc: 0.9468 - f1_m: 0.93 - 0s 25us/step - loss: 0.1589 - acc: 0.9445 - f1_m: 0.9284\n",
      "Epoch 2/5\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 0.1578 - acc: 0.9428 - f1_m: 0.9237\n",
      "Epoch 3/5\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 0.1531 - acc: 0.9449 - f1_m: 0.9280\n",
      "Epoch 4/5\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 0.1606 - acc: 0.9396 - f1_m: 0.9211\n",
      "Epoch 5/5\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 0.1520 - acc: 0.9449 - f1_m: 0.9260\n",
      "460/460 [==============================] - 0s 17us/step\n",
      "\n",
      "accuracy:   0.934, f1_score:   0.406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_accuracy = 0\n",
    "overall_f1_score = 0\n",
    "for train, test in kf.split(spambase_df):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = spambase_df.iloc[train], spambase_df.iloc[test], spambase_y.iloc[train], spambase_y.iloc[test]\n",
    "    \n",
    "    history = model.fit(X_train.values,\n",
    "                        y_train.values,\n",
    "                        epochs=5)\n",
    "    \n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    loss, accuracy, f1 = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    overall_accuracy += accuracy\n",
    "    overall_f1_score += f1\n",
    "    \n",
    "print(\"\\naccuracy:   %0.3f, f1_score:   %0.3f\\n\" % (overall_accuracy/10, overall_f1_score/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with 1 layer\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.sigmoid)) # 16 neurons and sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7328/7328 [==============================] - 0s 54us/step - loss: 6.5638 - acc: 0.5878 - f1_m: 0.4844\n",
      "Epoch 2/10\n",
      "7328/7328 [==============================] - 0s 22us/step - loss: 6.5486 - acc: 0.5885 - f1_m: 0.4865\n",
      "Epoch 3/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 6.5391 - acc: 0.5890 - f1_m: 0.4868\n",
      "Epoch 4/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 6.5386 - acc: 0.5888 - f1_m: 0.4858\n",
      "Epoch 5/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 6.1200 - acc: 0.6153 - f1_m: 0.4961\n",
      "Epoch 6/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 5.9693 - acc: 0.6247 - f1_m: 0.4981\n",
      "Epoch 7/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 5.9734 - acc: 0.6248 - f1_m: 0.5005\n",
      "Epoch 8/10\n",
      "7328/7328 [==============================] - 0s 22us/step - loss: 6.3474 - acc: 0.6019 - f1_m: 0.4737\n",
      "Epoch 9/10\n",
      "7328/7328 [==============================] - 0s 21us/step - loss: 6.5463 - acc: 0.5894 - f1_m: 0.4489\n",
      "Epoch 10/10\n",
      "7328/7328 [==============================] - 0s 21us/step - loss: 6.1296 - acc: 0.6166 - f1_m: 0.4571\n",
      "815/815 [==============================] - 0s 114us/step\n",
      "Epoch 1/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 5.6792 - acc: 0.6449 - f1_m: 0.4621\n",
      "Epoch 2/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 5.5533 - acc: 0.6529 - f1_m: 0.4627\n",
      "Epoch 3/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 5.5507 - acc: 0.6531 - f1_m: 0.4641\n",
      "Epoch 4/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 5.5531 - acc: 0.6529 - f1_m: 0.4636\n",
      "Epoch 5/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 5.5508 - acc: 0.6530 - f1_m: 0.4646\n",
      "Epoch 6/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 5.5501 - acc: 0.6531 - f1_m: 0.4646\n",
      "Epoch 7/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 5.5535 - acc: 0.6527 - f1_m: 0.4613\n",
      "Epoch 8/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 5.5516 - acc: 0.6530 - f1_m: 0.4635\n",
      "Epoch 9/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 5.5522 - acc: 0.6528 - f1_m: 0.4629\n",
      "Epoch 10/10\n",
      "7328/7328 [==============================] - 0s 21us/step - loss: 5.5495 - acc: 0.6531 - f1_m: 0.4637\n",
      "815/815 [==============================] - 0s 11us/step\n",
      "Epoch 1/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 5.5634 - acc: 0.6522 - f1_m: 0.4684\n",
      "Epoch 2/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 6.1847 - acc: 0.6136 - f1_m: 0.4159\n",
      "Epoch 3/10\n",
      "7328/7328 [==============================] - 0s 18us/step - loss: 6.2839 - acc: 0.6075 - f1_m: 0.4072\n",
      "Epoch 4/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 6.2839 - acc: 0.6075 - f1_m: 0.4072\n",
      "Epoch 5/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 6.2839 - acc: 0.6075 - f1_m: 0.4071\n",
      "Epoch 6/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 6.2839 - acc: 0.6075 - f1_m: 0.4071\n",
      "Epoch 7/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 6.2839 - acc: 0.6075 - f1_m: 0.4073\n",
      "Epoch 8/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 6.2839 - acc: 0.6075 - f1_m: 0.4073\n",
      "Epoch 9/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 6.2839 - acc: 0.6075 - f1_m: 0.4075\n",
      "Epoch 10/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 6.2839 - acc: 0.6075 - f1_m: 0.4073\n",
      "815/815 [==============================] - 0s 12us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4027\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4025\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4025\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4022\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4022\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4023\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 24us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4024\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 27us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4022\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 27us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4025\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 6.2677 - acc: 0.6084 - f1_m: 0.4027\n",
      "814/814 [==============================] - 0s 14us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4064\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4064\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4062\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4063\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4067\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4066\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4064\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4063\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4062\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2806 - acc: 0.6077 - f1_m: 0.4062\n",
      "814/814 [==============================] - 0s 15us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4067\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4065\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4067\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4068\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4068\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4068\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4065\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4066\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4067\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4067\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4094\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4094\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4094\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4095\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4096\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4095\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4097\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4098\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4093\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 6.2912 - acc: 0.6070 - f1_m: 0.4092\n",
      "814/814 [==============================] - 0s 12us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.3998\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.4000\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.3999\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.3997\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.3997\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.4000\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.3995\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.3996\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 18us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.3999\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2595 - acc: 0.6090 - f1_m: 0.3998\n",
      "814/814 [==============================] - 0s 14us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4064\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4067\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4066\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4069\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 24us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4067\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 26us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4063\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4069\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 24us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4066\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 23us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4062\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2820 - acc: 0.6076 - f1_m: 0.4065\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4081\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4081\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4080\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4081\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4082\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4083\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4081\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4080\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4081\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 22us/step - loss: 6.2870 - acc: 0.6073 - f1_m: 0.4081\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "\n",
      "accuracy:   0.613, f1_score:   0.377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_accuracy = 0\n",
    "overall_f1_score = 0\n",
    "for train, test in kf.split(occupancy_df_training):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = occupancy_df_training.iloc[train], occupancy_df_training.iloc[test], occupancy_y.iloc[train], occupancy_y.iloc[test]\n",
    "    \n",
    "    history = model.fit(X_train.values,\n",
    "                        y_train.values,\n",
    "                        epochs=10)\n",
    "    \n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    loss, accuracy, f1 = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    overall_accuracy += accuracy\n",
    "    overall_f1_score += f1\n",
    "    \n",
    "print(\"\\naccuracy:   %0.3f, f1_score:   %0.3f\\n\" % (overall_accuracy/10, overall_f1_score/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with 1 layer\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.sigmoid)) # 16 neurons and sigmoid activation function\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4140/4140 [==============================] - 0s 84us/step - loss: 2.7495 - acc: 0.5184 - f1_m: 0.7921\n",
      "Epoch 2/10\n",
      "4140/4140 [==============================] - 0s 24us/step - loss: 2.1967 - acc: 0.5316 - f1_m: 0.8303\n",
      "Epoch 3/10\n",
      "4140/4140 [==============================] - 0s 24us/step - loss: 2.2021 - acc: 0.5350 - f1_m: 0.8396\n",
      "Epoch 4/10\n",
      "4140/4140 [==============================] - 0s 25us/step - loss: 2.1663 - acc: 0.5481 - f1_m: 0.8583\n",
      "Epoch 5/10\n",
      "4140/4140 [==============================] - 0s 21us/step - loss: 2.1198 - acc: 0.5588 - f1_m: 0.8669\n",
      "Epoch 6/10\n",
      "4140/4140 [==============================] - 0s 21us/step - loss: 2.0580 - acc: 0.5757 - f1_m: 0.8910\n",
      "Epoch 7/10\n",
      "4140/4140 [==============================] - 0s 21us/step - loss: 2.2780 - acc: 0.5715 - f1_m: 0.8922\n",
      "Epoch 8/10\n",
      "4140/4140 [==============================] - 0s 25us/step - loss: 2.1291 - acc: 0.5765 - f1_m: 0.9030\n",
      "Epoch 9/10\n",
      "4140/4140 [==============================] - 0s 24us/step - loss: 2.1638 - acc: 0.5880 - f1_m: 0.9234\n",
      "Epoch 10/10\n",
      "4140/4140 [==============================] - 0s 23us/step - loss: 2.0909 - acc: 0.5910 - f1_m: 0.9267\n",
      "461/461 [==============================] - 0s 219us/step\n",
      "Epoch 1/10\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 2.1495 - acc: 0.5918 - f1_m: 0.9346\n",
      "Epoch 2/10\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 2.1889 - acc: 0.6005 - f1_m: 0.9612\n",
      "Epoch 3/10\n",
      "4141/4141 [==============================] - 0s 27us/step - loss: 2.0464 - acc: 0.6066 - f1_m: 0.9650\n",
      "Epoch 4/10\n",
      "4141/4141 [==============================] - 0s 26us/step - loss: 2.0524 - acc: 0.6118 - f1_m: 0.9848\n",
      "Epoch 5/10\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 1.9642 - acc: 0.6251 - f1_m: 0.9878\n",
      "Epoch 6/10\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 2.0469 - acc: 0.6180 - f1_m: 0.9839\n",
      "Epoch 7/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.8810 - acc: 0.6377 - f1_m: 1.0193\n",
      "Epoch 8/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.9427 - acc: 0.6386 - f1_m: 1.0154\n",
      "Epoch 9/10\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 1.9007 - acc: 0.6410 - f1_m: 1.0235\n",
      "Epoch 10/10\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 1.8914 - acc: 0.6439 - f1_m: 1.0304\n",
      "460/460 [==============================] - 0s 22us/step\n",
      "Epoch 1/10\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 1.9745 - acc: 0.6354 - f1_m: 1.0269\n",
      "Epoch 2/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 2.0975 - acc: 0.6296 - f1_m: 1.0078\n",
      "Epoch 3/10\n",
      "4141/4141 [==============================] - 0s 26us/step - loss: 2.0179 - acc: 0.6385 - f1_m: 1.0251\n",
      "Epoch 4/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.9801 - acc: 0.6459 - f1_m: 1.0354\n",
      "Epoch 5/10\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 1.9313 - acc: 0.6432 - f1_m: 1.0432\n",
      "Epoch 6/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.8777 - acc: 0.6523 - f1_m: 1.0501\n",
      "Epoch 7/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.9851 - acc: 0.6494 - f1_m: 1.0493\n",
      "Epoch 8/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.9852 - acc: 0.6484 - f1_m: 1.0431\n",
      "Epoch 9/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.9222 - acc: 0.6511 - f1_m: 1.0538\n",
      "Epoch 10/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.9048 - acc: 0.6606 - f1_m: 1.0678\n",
      "460/460 [==============================] - 0s 15us/step\n",
      "Epoch 1/10\n",
      "4141/4141 [==============================] - 0s 25us/step - loss: 1.8687 - acc: 0.6652 - f1_m: 1.0729\n",
      "Epoch 2/10\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 1.8874 - acc: 0.6649 - f1_m: 1.0674\n",
      "Epoch 3/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 2.0054 - acc: 0.6577 - f1_m: 1.0535\n",
      "Epoch 4/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.8037 - acc: 0.6724 - f1_m: 1.0914\n",
      "Epoch 5/10\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 1.9905 - acc: 0.6681 - f1_m: 1.0812\n",
      "Epoch 6/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.9697 - acc: 0.6640 - f1_m: 1.0705\n",
      "Epoch 7/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.8793 - acc: 0.6797 - f1_m: 1.0863\n",
      "Epoch 8/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8759 - acc: 0.6744 - f1_m: 1.0898\n",
      "Epoch 9/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.7618 - acc: 0.6806 - f1_m: 1.1043\n",
      "Epoch 10/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8554 - acc: 0.6722 - f1_m: 1.0943\n",
      "460/460 [==============================] - 0s 13us/step\n",
      "Epoch 1/10\n",
      "4141/4141 [==============================] - 0s 28us/step - loss: 1.8221 - acc: 0.6765 - f1_m: 1.1050\n",
      "Epoch 2/10\n",
      "4141/4141 [==============================] - 0s 26us/step - loss: 1.8260 - acc: 0.6787 - f1_m: 1.1233\n",
      "Epoch 3/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8137 - acc: 0.6754 - f1_m: 1.1066\n",
      "Epoch 4/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8121 - acc: 0.6825 - f1_m: 1.1217\n",
      "Epoch 5/10\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 1.8162 - acc: 0.6860 - f1_m: 1.1359\n",
      "Epoch 6/10\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 1.8550 - acc: 0.6787 - f1_m: 1.1128\n",
      "Epoch 7/10\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 1.7879 - acc: 0.6852 - f1_m: 1.1198\n",
      "Epoch 8/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.8073 - acc: 0.6785 - f1_m: 1.1129\n",
      "Epoch 9/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.7271 - acc: 0.6854 - f1_m: 1.1271\n",
      "Epoch 10/10\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 1.7751 - acc: 0.6876 - f1_m: 1.1279\n",
      "460/460 [==============================] - 0s 20us/step\n",
      "Epoch 1/10\n",
      "4141/4141 [==============================] - 0s 25us/step - loss: 1.7505 - acc: 0.6927 - f1_m: 1.1319\n",
      "Epoch 2/10\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 1.9112 - acc: 0.6771 - f1_m: 1.0977\n",
      "Epoch 3/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.8845 - acc: 0.6851 - f1_m: 1.1290\n",
      "Epoch 4/10\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 1.7825 - acc: 0.6882 - f1_m: 1.1396\n",
      "Epoch 5/10\n",
      "4141/4141 [==============================] - 0s 25us/step - loss: 1.7666 - acc: 0.6984 - f1_m: 1.1518\n",
      "Epoch 6/10\n",
      "4141/4141 [==============================] - 0s 24us/step - loss: 1.8466 - acc: 0.6802 - f1_m: 1.1114\n",
      "Epoch 7/10\n",
      "4141/4141 [==============================] - 0s 29us/step - loss: 1.8712 - acc: 0.6863 - f1_m: 1.1275\n",
      "Epoch 8/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8916 - acc: 0.6893 - f1_m: 1.1425\n",
      "Epoch 9/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8242 - acc: 0.6926 - f1_m: 1.1376\n",
      "Epoch 10/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7650 - acc: 0.7002 - f1_m: 1.1406\n",
      "460/460 [==============================] - 0s 17us/step\n",
      "Epoch 1/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.6664 - acc: 0.7030 - f1_m: 1.1731\n",
      "Epoch 2/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.7178 - acc: 0.6962 - f1_m: 1.1575\n",
      "Epoch 3/10\n",
      "4141/4141 [==============================] - 0s 26us/step - loss: 1.6769 - acc: 0.6951 - f1_m: 1.1569\n",
      "Epoch 4/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.8489 - acc: 0.6862 - f1_m: 1.1324\n",
      "Epoch 5/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.6492 - acc: 0.7023 - f1_m: 1.1748\n",
      "Epoch 6/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.6621 - acc: 0.7038 - f1_m: 1.1790\n",
      "Epoch 7/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.7494 - acc: 0.6971 - f1_m: 1.1547\n",
      "Epoch 8/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.7407 - acc: 0.6994 - f1_m: 1.1540\n",
      "Epoch 9/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8491 - acc: 0.6943 - f1_m: 1.1486\n",
      "Epoch 10/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8011 - acc: 0.7027 - f1_m: 1.1755\n",
      "460/460 [==============================] - 0s 15us/step\n",
      "Epoch 1/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.7386 - acc: 0.7036 - f1_m: 1.1822\n",
      "Epoch 2/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8032 - acc: 0.7013 - f1_m: 1.1809\n",
      "Epoch 3/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7427 - acc: 0.7021 - f1_m: 1.1677\n",
      "Epoch 4/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7811 - acc: 0.7022 - f1_m: 1.1603\n",
      "Epoch 5/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7635 - acc: 0.7012 - f1_m: 1.1579\n",
      "Epoch 6/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.8380 - acc: 0.7030 - f1_m: 1.1594\n",
      "Epoch 7/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7202 - acc: 0.7063 - f1_m: 1.1893\n",
      "Epoch 8/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8089 - acc: 0.7068 - f1_m: 1.1900\n",
      "Epoch 9/10\n",
      "4141/4141 [==============================] - 0s 22us/step - loss: 1.6520 - acc: 0.7129 - f1_m: 1.1873\n",
      "Epoch 10/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7454 - acc: 0.7042 - f1_m: 1.1720\n",
      "460/460 [==============================] - 0s 17us/step\n",
      "Epoch 1/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7750 - acc: 0.7085 - f1_m: 1.1873\n",
      "Epoch 2/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.5460 - acc: 0.7163 - f1_m: 1.2087\n",
      "Epoch 3/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8582 - acc: 0.6949 - f1_m: 1.1585\n",
      "Epoch 4/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.6682 - acc: 0.7075 - f1_m: 1.1889\n",
      "Epoch 5/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7582 - acc: 0.7021 - f1_m: 1.1749\n",
      "Epoch 6/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.6987 - acc: 0.7086 - f1_m: 1.1964\n",
      "Epoch 7/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7270 - acc: 0.7121 - f1_m: 1.1938\n",
      "Epoch 8/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.7170 - acc: 0.7119 - f1_m: 1.1908\n",
      "Epoch 9/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7912 - acc: 0.7076 - f1_m: 1.1753\n",
      "Epoch 10/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.7980 - acc: 0.7059 - f1_m: 1.1890\n",
      "460/460 [==============================] - 0s 15us/step\n",
      "Epoch 1/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7863 - acc: 0.7061 - f1_m: 1.1701\n",
      "Epoch 2/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.6702 - acc: 0.7199 - f1_m: 1.2051\n",
      "Epoch 3/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.6677 - acc: 0.7148 - f1_m: 1.1831\n",
      "Epoch 4/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.7277 - acc: 0.7105 - f1_m: 1.1764\n",
      "Epoch 5/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.6783 - acc: 0.7154 - f1_m: 1.1919\n",
      "Epoch 6/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.6545 - acc: 0.7239 - f1_m: 1.2061\n",
      "Epoch 7/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.8628 - acc: 0.7106 - f1_m: 1.1868\n",
      "Epoch 8/10\n",
      "4141/4141 [==============================] - 0s 20us/step - loss: 1.6644 - acc: 0.7267 - f1_m: 1.2235\n",
      "Epoch 9/10\n",
      "4141/4141 [==============================] - 0s 21us/step - loss: 1.8396 - acc: 0.7088 - f1_m: 1.1882\n",
      "Epoch 10/10\n",
      "4141/4141 [==============================] - 0s 23us/step - loss: 1.7001 - acc: 0.7150 - f1_m: 1.1844\n",
      "460/460 [==============================] - 0s 20us/step\n",
      "\n",
      "accuracy:   0.665, f1_score:   0.728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "overall_accuracy = 0\n",
    "overall_f1_score = 0\n",
    "for train, test in kf.split(spambase_df):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = spambase_df.iloc[train], spambase_df.iloc[test], spambase_y.iloc[train], spambase_y.iloc[test]\n",
    "    \n",
    "    history = model.fit(X_train.values,\n",
    "                        y_train.values,\n",
    "                        epochs=10)\n",
    "    \n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    loss, accuracy, f1 = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    overall_accuracy += accuracy\n",
    "    overall_f1_score += f1\n",
    "    \n",
    "print(\"\\naccuracy:   %0.3f, f1_score:   %0.3f\\n\" % (overall_accuracy/10, overall_f1_score/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
