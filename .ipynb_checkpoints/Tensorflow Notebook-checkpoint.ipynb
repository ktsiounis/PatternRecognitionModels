{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ntino\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
      "1  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25       0.004793   \n",
      "2  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00       0.004783   \n",
      "3  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50       0.004779   \n",
      "4  2015-02-04 17:54:00        23.15   27.2000  426.0  708.25       0.004772   \n",
      "5  2015-02-04 17:55:00        23.10   27.2000  426.0  704.50       0.004757   \n",
      "\n",
      "   Occupancy  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n",
      "5          1  \n",
      "     0     1     2    3     4     5     6     7     8     9  ...    48     49  \\\n",
      "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
      "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
      "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
      "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
      "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
      "\n",
      "    50     51     52     53     54   55    56  57  \n",
      "0  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
      "1  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
      "2  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
      "3  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
      "4  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "occupancy_df_training = pd.read_csv(\"occupancy_data/datatraining.txt\", header=0)\n",
    "\n",
    "print(occupancy_df_training.head())\n",
    "\n",
    "occupancy_df_test1 = pd.read_csv(\"occupancy_data/datatest.txt\", header=0)\n",
    "occupancy_df_test2 = pd.read_csv(\"occupancy_data/datatest2.txt\", header=0)\n",
    "\n",
    "spambase_df = pd.read_csv(\"spambase/spambase.data\", header=None)\n",
    "\n",
    "print(spambase_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_y = occupancy_df_training.Occupancy\n",
    "\n",
    "occupancy_df_training = occupancy_df_training.drop(\"Occupancy\", axis=1)\n",
    "occupancy_df_training = occupancy_df_training.drop(\"date\", axis=1)\n",
    "\n",
    "spambase_y = spambase_df[57]\n",
    "spambase_df = spambase_df.drop(57, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split with KFolds\n",
    "kf = KFold(10, True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with 2 layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.sigmoid)) # 16 neurons and sigmoid activation function\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid)) # 1 neuron and sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7328/7328 [==============================] - 0s 53us/step - loss: 0.7976 - acc: 0.4703 - f1_m: 0.3662\n",
      "Epoch 2/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.4618 - acc: 0.7878 - f1_m: 0.0000e+00\n",
      "Epoch 3/10\n",
      "7328/7328 [==============================] - 0s 21us/step - loss: 0.3683 - acc: 0.7878 - f1_m: 0.0000e+00\n",
      "Epoch 4/10\n",
      "7328/7328 [==============================] - 0s 21us/step - loss: 0.3196 - acc: 0.7878 - f1_m: 0.0000e+00\n",
      "Epoch 5/10\n",
      "7328/7328 [==============================] - 0s 21us/step - loss: 0.2862 - acc: 0.8619 - f1_m: 0.4461\n",
      "Epoch 6/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.2617 - acc: 0.9325 - f1_m: 0.8537\n",
      "Epoch 7/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.2416 - acc: 0.9331 - f1_m: 0.8554\n",
      "Epoch 8/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.2259 - acc: 0.9350 - f1_m: 0.8593\n",
      "Epoch 9/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.2138 - acc: 0.9341 - f1_m: 0.8584\n",
      "Epoch 10/10\n",
      "7328/7328 [==============================] - 0s 21us/step - loss: 0.2036 - acc: 0.9350 - f1_m: 0.8541\n",
      "815/815 [==============================] - 0s 82us/step\n",
      "\n",
      "accuracy:   0.940, f1_score:   0.362\n",
      "\n",
      "Epoch 1/10\n",
      "7328/7328 [==============================] - 0s 23us/step - loss: 0.1938 - acc: 0.9374 - f1_m: 0.8588\n",
      "Epoch 2/10\n",
      "7328/7328 [==============================] - 0s 23us/step - loss: 0.1872 - acc: 0.9370 - f1_m: 0.8644\n",
      "Epoch 3/10\n",
      "7328/7328 [==============================] - 0s 21us/step - loss: 0.1801 - acc: 0.9391 - f1_m: 0.8646\n",
      "Epoch 4/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1779 - acc: 0.9372 - f1_m: 0.8633\n",
      "Epoch 5/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1716 - acc: 0.9394 - f1_m: 0.8646\n",
      "Epoch 6/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.1686 - acc: 0.9391 - f1_m: 0.8682\n",
      "Epoch 7/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.1649 - acc: 0.9402 - f1_m: 0.8676\n",
      "Epoch 8/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1620 - acc: 0.9410 - f1_m: 0.8681\n",
      "Epoch 9/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.1580 - acc: 0.9420 - f1_m: 0.8720\n",
      "Epoch 10/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1534 - acc: 0.9443 - f1_m: 0.8728\n",
      "815/815 [==============================] - 0s 11us/step\n",
      "\n",
      "accuracy:   0.942, f1_score:   0.403\n",
      "\n",
      "Epoch 1/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1539 - acc: 0.9439 - f1_m: 0.8769\n",
      "Epoch 2/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1518 - acc: 0.9442 - f1_m: 0.8768\n",
      "Epoch 3/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1495 - acc: 0.9454 - f1_m: 0.8804\n",
      "Epoch 4/10\n",
      "7328/7328 [==============================] - 0s 19us/step - loss: 0.1477 - acc: 0.9458 - f1_m: 0.8782\n",
      "Epoch 5/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1441 - acc: 0.9481 - f1_m: 0.8849\n",
      "Epoch 6/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1434 - acc: 0.9479 - f1_m: 0.8855\n",
      "Epoch 7/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1397 - acc: 0.9501 - f1_m: 0.8858\n",
      "Epoch 8/10\n",
      "7328/7328 [==============================] - 0s 20us/step - loss: 0.1382 - acc: 0.9511 - f1_m: 0.8895\n",
      "Epoch 9/10\n",
      "7328/7328 [==============================] - 0s 22us/step - loss: 0.1346 - acc: 0.9532 - f1_m: 0.8903\n",
      "Epoch 10/10\n",
      "7328/7328 [==============================] - 0s 23us/step - loss: 0.1321 - acc: 0.9539 - f1_m: 0.8953\n",
      "815/815 [==============================] - 0s 12us/step\n",
      "\n",
      "accuracy:   0.977, f1_score:   0.368\n",
      "\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.1266 - acc: 0.9567 - f1_m: 0.9033\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.1213 - acc: 0.9593 - f1_m: 0.9054\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.1085 - acc: 0.9673 - f1_m: 0.9230\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0838 - acc: 0.9795 - f1_m: 0.9492\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0782 - acc: 0.9817 - f1_m: 0.9542\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0740 - acc: 0.9835 - f1_m: 0.9597\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0723 - acc: 0.9828 - f1_m: 0.9566\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0701 - acc: 0.9831 - f1_m: 0.9457\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0682 - acc: 0.9847 - f1_m: 0.9631\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0661 - acc: 0.9843 - f1_m: 0.9614\n",
      "814/814 [==============================] - 0s 10us/step\n",
      "\n",
      "accuracy:   0.986, f1_score:   0.358\n",
      "\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0636 - acc: 0.9847 - f1_m: 0.9594\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0625 - acc: 0.9850 - f1_m: 0.9632\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0609 - acc: 0.9853 - f1_m: 0.9616\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0599 - acc: 0.9862 - f1_m: 0.9662\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0610 - acc: 0.9847 - f1_m: 0.9632\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0578 - acc: 0.9864 - f1_m: 0.9672\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0562 - acc: 0.9870 - f1_m: 0.9668\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0551 - acc: 0.9876 - f1_m: 0.9685\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0550 - acc: 0.9869 - f1_m: 0.9652\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0540 - acc: 0.9865 - f1_m: 0.9593\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "\n",
      "accuracy:   0.985, f1_score:   0.401\n",
      "\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0561 - acc: 0.9866 - f1_m: 0.9650\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 21us/step - loss: 0.0547 - acc: 0.9866 - f1_m: 0.9686\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0534 - acc: 0.9872 - f1_m: 0.9683\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0529 - acc: 0.9877 - f1_m: 0.9696\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0520 - acc: 0.9879 - f1_m: 0.9645\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0520 - acc: 0.9869 - f1_m: 0.9674\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0513 - acc: 0.9879 - f1_m: 0.9679\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0507 - acc: 0.9876 - f1_m: 0.9670\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0503 - acc: 0.9879 - f1_m: 0.9602\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0506 - acc: 0.9873 - f1_m: 0.9676\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "\n",
      "accuracy:   0.993, f1_score:   0.365\n",
      "\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0460 - acc: 0.9888 - f1_m: 0.9721\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0453 - acc: 0.9889 - f1_m: 0.9719\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0459 - acc: 0.9891 - f1_m: 0.9706\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0448 - acc: 0.9889 - f1_m: 0.9714\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0450 - acc: 0.9889 - f1_m: 0.9731\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0470 - acc: 0.9889 - f1_m: 0.9713\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0458 - acc: 0.9889 - f1_m: 0.9699\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0459 - acc: 0.9885 - f1_m: 0.9692\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0451 - acc: 0.9885 - f1_m: 0.9725\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0439 - acc: 0.9889 - f1_m: 0.9700\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "\n",
      "accuracy:   0.980, f1_score:   0.357\n",
      "\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0466 - acc: 0.9884 - f1_m: 0.9723\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0482 - acc: 0.9866 - f1_m: 0.9666\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0461 - acc: 0.9881 - f1_m: 0.9697\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0469 - acc: 0.9881 - f1_m: 0.9695\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0463 - acc: 0.9884 - f1_m: 0.9692\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0454 - acc: 0.9883 - f1_m: 0.9706\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0460 - acc: 0.9884 - f1_m: 0.9671\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0467 - acc: 0.9883 - f1_m: 0.9633\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0474 - acc: 0.9884 - f1_m: 0.9701\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0469 - acc: 0.9884 - f1_m: 0.9700\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "\n",
      "accuracy:   0.988, f1_score:   0.402\n",
      "\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0518 - acc: 0.9857 - f1_m: 0.9629\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0480 - acc: 0.9876 - f1_m: 0.9712\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0466 - acc: 0.9883 - f1_m: 0.9735\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0474 - acc: 0.9883 - f1_m: 0.9721\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0474 - acc: 0.9881 - f1_m: 0.9711\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0463 - acc: 0.9881 - f1_m: 0.9706\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0469 - acc: 0.9880 - f1_m: 0.9691\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0482 - acc: 0.9877 - f1_m: 0.9686\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0473 - acc: 0.9877 - f1_m: 0.9693\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0476 - acc: 0.9870 - f1_m: 0.9661\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "\n",
      "accuracy:   0.989, f1_score:   0.398\n",
      "\n",
      "Epoch 1/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0457 - acc: 0.9884 - f1_m: 0.9715\n",
      "Epoch 2/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0455 - acc: 0.9881 - f1_m: 0.9721\n",
      "Epoch 3/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0458 - acc: 0.9883 - f1_m: 0.9720\n",
      "Epoch 4/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0454 - acc: 0.9883 - f1_m: 0.9700\n",
      "Epoch 5/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0451 - acc: 0.9884 - f1_m: 0.9716\n",
      "Epoch 6/10\n",
      "7329/7329 [==============================] - 0s 19us/step - loss: 0.0452 - acc: 0.9884 - f1_m: 0.9734\n",
      "Epoch 7/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0457 - acc: 0.9881 - f1_m: 0.9687\n",
      "Epoch 8/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0457 - acc: 0.9884 - f1_m: 0.9725\n",
      "Epoch 9/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0462 - acc: 0.9883 - f1_m: 0.9692\n",
      "Epoch 10/10\n",
      "7329/7329 [==============================] - 0s 20us/step - loss: 0.0450 - acc: 0.9883 - f1_m: 0.9700\n",
      "814/814 [==============================] - 0s 11us/step\n",
      "\n",
      "accuracy:   0.988, f1_score:   0.363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train, test in kf.split(occupancy_df_training):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = occupancy_df_training.iloc[train], occupancy_df_training.iloc[test], occupancy_y.iloc[train], occupancy_y.iloc[test]\n",
    "    \n",
    "    history = model.fit(X_train.values,\n",
    "                        y_train.values,\n",
    "                        epochs=10)\n",
    "    \n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    loss, accuracy, f1 = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    print(\"\\naccuracy:   %0.3f, f1_score:   %0.3f\\n\" % (accuracy, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
